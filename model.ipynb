{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426f9a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Users/mitaliagrawal/Library/Python/3.9/lib/python/site-packages (2.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mitaliagrawal/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mitaliagrawal/Library/Python/3.9/lib/python/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mitaliagrawal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/mitaliagrawal/Library/Python/3.9/lib/python/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba99d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Rank       Country\n",
      "0       1st       Finland\n",
      "1       2nd       Ireland\n",
      "2       3rd        Norway\n",
      "3       4th        France\n",
      "4       5th   Netherlands\n",
      "..      ...           ...\n",
      "108  =108th    Madagascar\n",
      "109   110th  Sierra Leone\n",
      "110   111th         Yemen\n",
      "111   112th         Haiti\n",
      "112   113th         Syria\n",
      "\n",
      "[113 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv('Global_Food_Security_Index.csv')\n",
    "\n",
    "lpi_data = df[['Rank', 'Country']]\n",
    "print(lpi_data)\n",
    "lpi_data.to_csv(\"analyzed_food_security_by_country.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a5b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total countries with complete data: 82\n",
      "\n",
      "First few rows:\n",
      "       Country Rank  Climate Stress Index      FSECI  LPI Score\n",
      "0      Finland    1              0.448973  59.695265        4.2\n",
      "1      Ireland    2              0.527122  58.139089        3.6\n",
      "2       Norway    3              0.480954  57.615069        3.7\n",
      "3       France    4              0.547296  61.050421        3.9\n",
      "4  Netherlands    5              0.537096  58.373274        4.1\n",
      "\n",
      "Missing values:\n",
      "Country                 0\n",
      "Rank                    0\n",
      "Climate Stress Index    0\n",
      "FSECI                   0\n",
      "LPI Score               0\n",
      "dtype: int64\n",
      "\n",
      "Feature statistics:\n",
      "       LPI Score      FSECI  Climate Stress Index\n",
      "count  82.000000  82.000000             82.000000\n",
      "mean    3.174390  56.748611              0.505519\n",
      "std     0.590001   3.269983              0.027558\n",
      "min     2.100000  41.669479              0.448973\n",
      "25%     2.700000  55.134345              0.492047\n",
      "50%     3.200000  57.068107              0.505130\n",
      "75%     3.700000  58.370608              0.521141\n",
      "max     4.300000  64.020172              0.554581\n",
      "\n",
      "Training set size: 65\n",
      "Test set size: 17\n",
      "\n",
      "Training Random Forest model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '=14'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 84\u001b[0m\n\u001b[1;32m     74\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m     75\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,      \u001b[38;5;66;03m# Number of trees\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,          \u001b[38;5;66;03m# Maximum depth of trees\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m              \u001b[38;5;66;03m# Use all CPU cores\u001b[39;00m\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining Random Forest model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 84\u001b[0m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     87\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_forest.py:422\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    419\u001b[0m y, expanded_class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_y_class_weight(y)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m!=\u001b[39m DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mcontiguous:\n\u001b[0;32m--> 422\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascontiguousarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDOUBLE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expanded_class_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '=14'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the CSV files\n",
    "csi_df = pd.read_csv('analyzed_climate_stress_by_country.csv')\n",
    "fseci_df = pd.read_csv('analyzed_FSECI_by_country.csv')\n",
    "lpi_df = pd.read_csv('analyzedLPI_by_country.csv')\n",
    "rank_df = pd.read_csv('analyzed_food_security_by_country.csv')\n",
    "\n",
    "# Clean column names (remove extra spaces)\n",
    "csi_df.columns = csi_df.columns.str.strip()\n",
    "fseci_df.columns = fseci_df.columns.str.strip()\n",
    "lpi_df.columns = lpi_df.columns.str.strip()\n",
    "rank_df.columns = rank_df.columns.str.strip()\n",
    "\n",
    "# Standardize country names for merging\n",
    "def clean_country_name(name):\n",
    "    return name.strip().lower()\n",
    "\n",
    "csi_df['Country_clean'] = csi_df['Country'].apply(clean_country_name)\n",
    "fseci_df['Country_clean'] = fseci_df['Country'].apply(clean_country_name)\n",
    "rank_df['Country_clean'] = rank_df['Country'].apply(clean_country_name)\n",
    "\n",
    "# For LPI, the country column might be named 'Economy'\n",
    "if 'Economy' in lpi_df.columns:\n",
    "    lpi_df['Country_clean'] = lpi_df['Economy'].apply(clean_country_name)\n",
    "else:\n",
    "    lpi_df['Country_clean'] = lpi_df['Country'].apply(clean_country_name)\n",
    "\n",
    "# Merge all datasets\n",
    "merged_df = rank_df[['Country', 'Country_clean', 'Rank']].copy()\n",
    "merged_df = merged_df.merge(csi_df[['Country_clean', 'Climate Stress Index']], \n",
    "                             on='Country_clean', how='inner')\n",
    "merged_df = merged_df.merge(fseci_df[['Country_clean', 'FSECI']], \n",
    "                             on='Country_clean', how='inner')\n",
    "merged_df = merged_df.merge(lpi_df[['Country_clean', 'LPI Score']], \n",
    "                             on='Country_clean', how='inner')\n",
    "\n",
    "# Remove the temporary clean column\n",
    "merged_df = merged_df.drop('Country_clean', axis=1)\n",
    "\n",
    "print(f\"Total countries with complete data: {len(merged_df)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "# Remove any rows with missing values\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = merged_df[['LPI Score', 'FSECI', 'Climate Stress Index']]\n",
    "y = merged_df['Rank']\n",
    "\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(X.describe())\n",
    "\n",
    "# Split data into train and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")\n",
    "\n",
    "# Create and train Random Forest model\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,      # Number of trees\n",
    "    max_depth=10,          # Maximum depth of trees\n",
    "    min_samples_split=5,   # Minimum samples required to split\n",
    "    min_samples_leaf=2,    # Minimum samples required at leaf node\n",
    "    random_state=42,\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  R² Score: {train_r2:.4f}\")\n",
    "print(f\"  RMSE: {train_rmse:.2f}\")\n",
    "print(f\"  MAE: {train_mae:.2f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  R² Score: {test_r2:.4f}\")\n",
    "print(f\"  RMSE: {test_rmse:.2f}\")\n",
    "print(f\"  MAE: {test_mae:.2f}\")\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=5, \n",
    "                            scoring='r2', n_jobs=-1)\n",
    "print(f\"\\n5-Fold Cross-Validation R² Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FEATURE IMPORTANCE\")\n",
    "print(\"=\"*50)\n",
    "print(feature_importance)\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Feature Importance\n",
    "axes[0, 0].barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "axes[0, 0].set_xlabel('Importance')\n",
    "axes[0, 0].set_title('Feature Importance')\n",
    "axes[0, 0].invert_yaxis()\n",
    "\n",
    "# 2. Actual vs Predicted (Test Set)\n",
    "axes[0, 1].scatter(y_test, y_test_pred, alpha=0.6)\n",
    "axes[0, 1].plot([y_test.min(), y_test.max()], \n",
    "                [y_test.min(), y_test.max()], \n",
    "                'r--', lw=2)\n",
    "axes[0, 1].set_xlabel('Actual Rank')\n",
    "axes[0, 1].set_ylabel('Predicted Rank')\n",
    "axes[0, 1].set_title(f'Actual vs Predicted (Test Set)\\nR² = {test_r2:.4f}')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuals Plot\n",
    "residuals = y_test - y_test_pred\n",
    "axes[1, 0].scatter(y_test_pred, residuals, alpha=0.6)\n",
    "axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 0].set_xlabel('Predicted Rank')\n",
    "axes[1, 0].set_ylabel('Residuals')\n",
    "axes[1, 0].set_title('Residual Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Error Distribution\n",
    "axes[1, 1].hist(residuals, bins=20, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 1].set_xlabel('Prediction Error')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Distribution of Prediction Errors')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('rf_model_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nVisualization saved as 'rf_model_results.png'\")\n",
    "\n",
    "# Create detailed predictions dataframe\n",
    "test_results = pd.DataFrame({\n",
    "    'Country': merged_df.loc[y_test.index, 'Country'].values,\n",
    "    'Actual_Rank': y_test.values,\n",
    "    'Predicted_Rank': y_test_pred,\n",
    "    'Error': np.abs(y_test.values - y_test_pred),\n",
    "    'LPI_Score': X_test['LPI Score'].values,\n",
    "    'FSECI': X_test['FSECI'].values,\n",
    "    'Climate_Stress_Index': X_test['Climate Stress Index'].values\n",
    "})\n",
    "\n",
    "test_results = test_results.sort_values('Actual_Rank')\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEST SET PREDICTIONS (sorted by actual rank)\")\n",
    "print(\"=\"*50)\n",
    "print(test_results.to_string(index=False))\n",
    "\n",
    "# Save predictions to CSV\n",
    "test_results.to_csv('predictions.csv', index=False)\n",
    "print(\"\\nPredictions saved to 'predictions.csv'\")\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "correlation_df = merged_df[['Rank', 'LPI Score', 'FSECI', 'Climate Stress Index']].corr()\n",
    "print(correlation_df)\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_df, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nCorrelation matrix saved as 'correlation_matrix.png'\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc14c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
